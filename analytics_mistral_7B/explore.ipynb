{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
    "df = load_from_disk(\"analytics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length(ex):\n",
    "    ex[\"Length\"] = len(tokenizer(ex[\"article\"])[\"input_ids\"])\n",
    "    return ex\n",
    "\n",
    "df = df.map(get_length, num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "collect_df = {\"ID\" : [],\n",
    "             \"Layer_Cut\" : [],\n",
    "             \"Sequence_Length\" : [],\n",
    "             \"Logits\" : [],\n",
    "             \"Tokens\" : [],\n",
    "             \"Length\" : [],\n",
    "             \"text_size\" : []}\n",
    "\n",
    "i = 0\n",
    "for element in tqdm(df):\n",
    "    for col in [v for v in element.keys() if \"_\" in v]:\n",
    "        collect_df[\"ID\"].append(i)\n",
    "    \n",
    "        sl, lc = col.split(\"_\")\n",
    "        \n",
    "        collect_df[\"Layer_Cut\"].append(lc)\n",
    "        collect_df[\"Sequence_Length\"].append(sl)\n",
    "        collect_df[\"Logits\"].append(element[col][\"top_5_l\"])\n",
    "        collect_df[\"Tokens\"].append(element[col][\"top_5_i\"])\n",
    "        collect_df[\"Length\"].append(element[col][\"length\"])\n",
    "        collect_df[\"text_size\"].append(element[\"Length\"])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(collect_df)\n",
    "df[\"Sequence_Length\"] = df[\"Sequence_Length\"].astype(int)\n",
    "df[\"Layer_Cut\"] = df[\"Layer_Cut\"].astype(int)\n",
    "df.to_json(\"analytics_slerp.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"text_size\"] > df[\"Sequence_Length\"]].drop(\"text_size\", axis = 1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df_gs = df[df[\"Layer_Cut\"] == 40]\n",
    "df_compare = df[df[\"Layer_Cut\"] != 40]\n",
    "\n",
    "df_gs = df_gs[[\"ID\", \"Sequence_Length\", \"Tokens\"]]\n",
    "df_gs[\"Tokens\"] = [v[0] for v in df_gs[\"Tokens\"]]\n",
    "\n",
    "df_compare = df_compare[[\"ID\", \"Layer_Cut\", \"Sequence_Length\", \"Tokens\"]]\n",
    "df_compare[\"Tokens\"] = [v[0] for v in df_compare[\"Tokens\"]]\n",
    "\n",
    "acc_check = pd.merge(df_compare, df_gs, on = [\"ID\", \"Sequence_Length\"], suffixes=[\"_bench\", \"_true\"])\n",
    "acc_check[\"Acc\"] = acc_check[\"Tokens_bench\"] == acc_check[\"Tokens_true\"]\n",
    "acc_check[\"Acc\"] = acc_check[\"Acc\"].astype(int)\n",
    "\n",
    "to_plot_acc = acc_check.drop([\"Tokens_bench\", \"Tokens_true\", \"ID\"], axis = 1).groupby([\"Layer_Cut\", \"Sequence_Length\"]).mean().reset_index()\n",
    "to_plot_acc[\"Sequence_Length\"] = to_plot_acc[\"Sequence_Length\"].astype(str)\n",
    "\n",
    "sns.lineplot(data=to_plot_acc, x=\"Layer_Cut\", y = \"Acc\", hue = \"Sequence_Length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gs = df[df[\"Layer_Cut\"] == 40]\n",
    "df_compare = df[df[\"Layer_Cut\"] != 40]\n",
    "\n",
    "df_gs = df_gs[[\"ID\", \"Sequence_Length\", \"Tokens\"]]\n",
    "df_gs[\"Tokens\"] = [v[0] for v in df_gs[\"Tokens\"]]\n",
    "\n",
    "df_compare = df_compare[[\"ID\", \"Layer_Cut\", \"Sequence_Length\", \"Tokens\"]]\n",
    "df_compare[\"Tokens\"] = [v[:3] for v in df_compare[\"Tokens\"]]\n",
    "\n",
    "acc_check = pd.merge(df_compare, df_gs, on = [\"ID\", \"Sequence_Length\"], suffixes=[\"_bench\", \"_true\"])\n",
    "acc_check[\"Acc\"] = [acc_check[\"Tokens_true\"][i] in acc_check[\"Tokens_bench\"][i] for i in range(acc_check.shape[0])]\n",
    "acc_check[\"Acc\"] = acc_check[\"Acc\"].astype(int)\n",
    "\n",
    "to_plot_acc = acc_check.drop([\"Tokens_bench\", \"Tokens_true\", \"ID\"], axis = 1).groupby([\"Layer_Cut\", \"Sequence_Length\"]).mean().reset_index()\n",
    "to_plot_acc[\"Sequence_Length\"] = to_plot_acc[\"Sequence_Length\"].astype(str)\n",
    "\n",
    "sns.lineplot(data=to_plot_acc, x=\"Layer_Cut\", y = \"Acc\", hue = \"Sequence_Length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gs = df[df[\"Layer_Cut\"] == 40]\n",
    "df_compare = df[df[\"Layer_Cut\"] != 40]\n",
    "\n",
    "df_gs = df_gs[[\"ID\", \"Sequence_Length\", \"Tokens\"]]\n",
    "df_gs[\"Tokens\"] = [v[0] for v in df_gs[\"Tokens\"]]\n",
    "\n",
    "df_compare = df_compare[[\"ID\", \"Layer_Cut\", \"Sequence_Length\", \"Tokens\"]]\n",
    "df_compare[\"Tokens\"] = [v[:5] for v in df_compare[\"Tokens\"]]\n",
    "\n",
    "acc_check = pd.merge(df_compare, df_gs, on = [\"ID\", \"Sequence_Length\"], suffixes=[\"_bench\", \"_true\"])\n",
    "acc_check[\"Acc\"] = [acc_check[\"Tokens_true\"][i] in acc_check[\"Tokens_bench\"][i] for i in range(acc_check.shape[0])]\n",
    "acc_check[\"Acc\"] = acc_check[\"Acc\"].astype(int)\n",
    "\n",
    "to_plot_acc = acc_check.drop([\"Tokens_bench\", \"Tokens_true\", \"ID\"], axis = 1).groupby([\"Layer_Cut\", \"Sequence_Length\"]).mean().reset_index()\n",
    "to_plot_acc[\"Sequence_Length\"] = to_plot_acc[\"Sequence_Length\"].astype(str)\n",
    "\n",
    "sns.lineplot(data=to_plot_acc, x=\"Layer_Cut\", y = \"Acc\", hue = \"Sequence_Length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_elements(list1, list2):\n",
    "    \"\"\"\n",
    "    Get the number of common elements between two lists.\n",
    "    \n",
    "    Args:\n",
    "    list1: First list.\n",
    "    list2: Second list.\n",
    "    \n",
    "    Returns:\n",
    "    Number of common elements between the two lists.\n",
    "    \"\"\"\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "    common = set1.intersection(set2)\n",
    "    return len(common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gs = df[df[\"Layer_Cut\"] == 40]\n",
    "df_compare = df[df[\"Layer_Cut\"] != 40]\n",
    "\n",
    "df_gs = df_gs[[\"ID\", \"Sequence_Length\", \"Tokens\"]]\n",
    "df_gs[\"Tokens\"] = [v[:5] for v in df_gs[\"Tokens\"]]\n",
    "\n",
    "df_compare = df_compare[[\"ID\", \"Layer_Cut\", \"Sequence_Length\", \"Tokens\"]]\n",
    "df_compare[\"Tokens\"] = [v[:5] for v in df_compare[\"Tokens\"]]\n",
    "\n",
    "acc_check = pd.merge(df_compare, df_gs, on = [\"ID\", \"Sequence_Length\"], suffixes=[\"_bench\", \"_true\"])\n",
    "acc_check[\"Acc\"] = [common_elements(acc_check[\"Tokens_true\"][i], acc_check[\"Tokens_bench\"][i]) for i in range(acc_check.shape[0])]\n",
    "acc_check[\"Acc\"] = acc_check[\"Acc\"].astype(int)\n",
    "\n",
    "to_plot_acc = acc_check.drop([\"Tokens_bench\", \"Tokens_true\", \"ID\"], axis = 1).groupby([\"Layer_Cut\", \"Sequence_Length\"]).mean().reset_index()\n",
    "to_plot_acc[\"Sequence_Length\"] = to_plot_acc[\"Sequence_Length\"].astype(str)\n",
    "\n",
    "sns.lineplot(data=to_plot_acc, x=\"Layer_Cut\", y = \"Acc\", hue = \"Sequence_Length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cross_entropy(logits1, logits2):\n",
    "    \"\"\"\n",
    "    Calculate the cross entropy between two lists of logits.\n",
    "    \n",
    "    Args:\n",
    "    logits1: List of logits (raw predictions) from the first model.\n",
    "    logits2: List of logits (raw predictions) from the second model.\n",
    "    \n",
    "    Returns:\n",
    "    Cross entropy between the two sets of logits.\n",
    "    \"\"\"\n",
    "    # Convert logits to probabilities\n",
    "    probs1 = np.exp(logits1 - np.max(logits1)) / np.sum(np.exp(logits1 - np.max(logits1)))\n",
    "    probs2 = np.exp(logits2 - np.max(logits2)) / np.sum(np.exp(logits2 - np.max(logits2)))\n",
    "    \n",
    "    # Avoiding log(0) by adding a small epsilon\n",
    "    epsilon = 1e-10\n",
    "    \n",
    "    # Calculate cross entropy\n",
    "    cross_entropy = -np.sum(probs1 * np.log(probs2 + epsilon))\n",
    "    \n",
    "    return cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gs = df[df[\"Layer_Cut\"] == 40]\n",
    "df_compare = df[df[\"Layer_Cut\"] != 40]\n",
    "\n",
    "df_gs = df_gs[[\"ID\", \"Sequence_Length\", \"Logits\"]]\n",
    "\n",
    "df_compare = df_compare[[\"ID\", \"Layer_Cut\", \"Sequence_Length\", \"Logits\"]]\n",
    "\n",
    "acc_check = pd.merge(df_compare, df_gs, on = [\"ID\", \"Sequence_Length\"], suffixes=[\"_bench\", \"_true\"])\n",
    "acc_check[\"CCE\"] = [cross_entropy(acc_check[\"Logits_true\"][i], acc_check[\"Logits_bench\"][i]) for i in range(acc_check.shape[0])]\n",
    "\n",
    "to_plot_acc = acc_check.drop([\"Logits_bench\", \"Logits_true\", \"ID\"], axis = 1).groupby([\"Layer_Cut\", \"Sequence_Length\"]).mean().reset_index()\n",
    "to_plot_acc[\"Sequence_Length\"] = to_plot_acc[\"Sequence_Length\"].astype(str)\n",
    "\n",
    "sns.lineplot(data=to_plot_acc, x=\"Layer_Cut\", y = \"CCE\", hue = \"Sequence_Length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gs = df[df[\"Layer_Cut\"] == 40]\n",
    "df_compare = df[df[\"Layer_Cut\"] != 40]\n",
    "\n",
    "df_gs = df_gs[[\"ID\", \"Sequence_Length\", \"Length\"]]\n",
    "\n",
    "df_compare = df_compare[[\"ID\", \"Layer_Cut\", \"Sequence_Length\", \"Length\"]]\n",
    "\n",
    "acc_check = pd.merge(df_compare, df_gs, on = [\"ID\", \"Sequence_Length\"], suffixes=[\"_bench\", \"_true\"])\n",
    "acc_check[\"faster\"] = [acc_check[\"Length_bench\"][i]/acc_check[\"Length_true\"][i] for i in range(acc_check.shape[0])]\n",
    "\n",
    "to_plot_acc = acc_check.drop([\"Length_bench\", \"Length_true\", \"ID\"], axis = 1).groupby([\"Layer_Cut\", \"Sequence_Length\"]).mean().reset_index()\n",
    "to_plot_acc[\"Sequence_Length\"] = to_plot_acc[\"Sequence_Length\"].astype(str)\n",
    "\n",
    "sns.lineplot(data=to_plot_acc, x=\"Layer_Cut\", y = \"faster\", hue = \"Sequence_Length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nuvocare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
