{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f209c9d5-b78d-436a-8b97-624fdbc53072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "merge_model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
    "\n",
    "merge_model = merge_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5db4997-6257-4dc0-b747-39859cff5db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "df = load_dataset(\"cnn_dailymail\",  \"1.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c28671f-e517-4d57-956f-baa8228ecd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from transformers import Pipeline\n",
    "from torch import Tensor\n",
    "from adpated_forward_call import run_merge\n",
    "\n",
    "class MyPipeline(Pipeline):\n",
    "    def _sanitize_parameters(self,\n",
    "                             **kwargs):\n",
    "        preprocess_kwargs = {}\n",
    "        if \"maybe_arg\" in kwargs:\n",
    "            preprocess_kwargs[\"maybe_arg\"] = kwargs[\"maybe_arg\"]\n",
    "        return preprocess_kwargs, {}, {}\n",
    "\n",
    "    def preprocess(self, inputs):\n",
    "        inputs = self.tokenizer(inputs, return_tensors = \"pt\", max_length = self.sl, truncation = True)\n",
    "        model_input = Tensor(inputs[\"input_ids\"][:,:self.sl])\n",
    "        return {\"model_input\": model_input}\n",
    "\n",
    "    def _forward(self, model_inputs):\n",
    "        logits, length = run_merge(model_inputs[\"model_input\"], self.lc, self.model)\n",
    "        return {\"logits\" : logits, \"length\" : length}\n",
    "\n",
    "    def postprocess(self, model_outputs):\n",
    "        top_5_l, top_5_i = torch.topk(model_outputs[\"logits\"], k=5, dim=-1)\n",
    "        top_5_l = top_5_l[0,-1,:]\n",
    "        top_5_i = top_5_i[0,-1,:]\n",
    "        return {\"top_5_l\" : top_5_l.numpy(),\n",
    "                \"top_5_i\" : top_5_i.numpy(),\n",
    "                \"length\" : model_outputs[\"length\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6976d0-743c-4f18-a0a1-6401fab73761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "\n",
    "check_df = df[\"train\"].shuffle().select(range(5000))\n",
    "\n",
    "k_df = KeyDataset(check_df, \"article\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7cea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = MyPipeline(model = merge_model, \n",
    "                              tokenizer = tokenizer,\n",
    "                              device = 0,\n",
    "                              num_workers = 8)\n",
    "pipeline.sl = 516 # Change this\n",
    "pipeline.lc = 8 # Change this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e7e2cb-365f-43d3-b9d1-3f262f884858",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lengths = [4, 8, 16]\n",
    "layer_cut = [40, 28, 16, 12, 4, 2]\n",
    "\n",
    "for res in pipeline(k_df):\n",
    "    print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hugging Face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
